# 04、Java 线程原理

## Java 内存模型

### 两个关键的问题

- 线程间如何通信？即线程之间怎么交换信息；
- 线程间如何同步？即线程之间是如何控制执行的先后顺序的。

两种并发模型：

![](https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-01.png)

<center>图01 两种并发模型的比较</center>
其中，**Java 是使用共享内存并发模型**。

### 运行时内存的划分

![](https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-02.png)

<center>图02 Java运行时数据区</center>
-  对于每一个线程来说，栈都是私有的，而堆是共有的 
  -  在栈中的变量（局部变量、方法定义参数、异常处理器参数）不会在线程之间共享,也就不会存在可见性问题；
  -  而在堆中的变量是共享的 ，所以，内存可见性是针对的**共享变量**。

###  Java内存模型（简称 JMM） 

**Java内存模型解决什么问题？**

解决线程读取数据高效的问题， 因为 CPU 访问缓存区( 缓存、写缓冲区、寄存器 ) 的速度比访问内存的速度快得多。这样就需要将内存的数据缓存到缓存区中，方便CPU访问。

- Java线程之间的通信由 JMM 控制；
- 从抽象的角度来说，JMM 定义了线程和主内存之间的抽象关系。

**Java内存模型结构**

<img src="https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-03.jpg" style="zoom: 50%;" />

<center>图03 JMM抽象示意图</center>
**特点：**

1. 所有的共享变量都存在主内存中；
2. 每个线程都保存了一份该线程使用到的共享变量的副本；
3. 如果 A、B 线程之间需要通信：
   -  线程 A 将本地内存 A 中更新过的共享变量刷新到主内存中去 ;
   -  线程 B 读取本地内存 B 中的变量时，发现本地内存 B 中 变量已经更新， 然后本地内存B去主内存中读取这个共享变量的新值，并拷贝到本地内存B中；
   - 最后线程 B 再读取本地内存B中的新值 。

> 以上的特点有两个规定：
>
> - 线程之间无法直接通信： **线程A无法直接访问线程B的工作内存，线程间通信必须经过主内存** 
> - 线程只能读取本地内存： 根据JMM的规定，**线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取** 
> - 实现同步机制的主角: JMM
>
> 可见性：
>
> -  volatile 关键字可以保证多线程操作共享变量的**可见性**以及禁止指令重排序；
> -  synchronized 关键字不仅保证**可见性**，同时也保证了原子性（互斥性） 

### JMM 与 Java 内存区域划分的区别和联系

- 区别：
  - 两者是不同的概念层次。JMM是抽象的，他是用来描述一组规则，通过这个规则来控制各个变量的访问方式，围绕原子性、有序性、可见性等展开的。 而Java运行时内存的划分是具体的，是JVM运行Java程序时，必要的内存划分。 
-  联系 
  - 都存在私有数据区域和共享数据区域。
  - JMM 中的主内存属于共享数据区域 ，它是包含了堆和方法区；
  - JMM 中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。

## 重排序与happens-before

### 重排序

**重排序**：计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。

#### 为什么需要重排序？

简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，**流水线技术**产生了，它的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。 

例子 1：

```java
a = b + c;
d = e - f ;
```

先加载b、c（**注意，即有可能先加载b，也有可能先加载c**），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。 

以上可总结为：

- 重排序减少了中断操作，使程序能根据流程的运行；
- 重排序对于提高CPU处理器性能十分必要，但是会带来乱序的问题。

**重排序有三种**

1. 编译器优化重排

   编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

2. 指令并行重排

   现代处理器采用了指令级并行技术来将多条指令重叠执行。如果**不存在数据依赖性**(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。 

3.  内存系统重排

   由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

 **指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致**。

### 顺序一致性模型

顺序一致性内存模型是一个**理想化的理论参考模型**，它为程序员提供了极强的内存可见性保证。

两大特性：

- 一个线程中的所有操作必须按照程序的顺序（即Java代码的顺序）来执行。 
- 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。即在顺序一致性模型中，每个操作必须是**原子性的，且立刻对所有线程可见**。 

例子2： 例子，假设有两个线程A和B并发执行，线程A有3个操作，他们在程序中的顺序是A1->A2->A3，线程B也有3个操作，B1->B2->B3。 

- 假设**正确使用了同步**，A线程的3个操作执行后释放锁，B线程获取同一个锁。那么在**顺序一致性模型**中的执行效果如下所示： 

  A1 -> A2 -> A3 -> B1 -> B2 -> B3 

  操作的执行整体上有序，并且两个线程都只能看到这个执行顺序。

- 假设**没有使用同步**，那么在**顺序一致性模型**中的执行效果如下所示：

  B1  -> A1 -> A2  -> B2  -> A3  -> B3 

  操作的执行整体上无序，但是两个线程都只能看到这个执行顺序。之所以可以得到这个保证，是因为顺序一致性模型中的**每个操作必须立即对任意线程可见**。

**JMM没有这样的保证顺序一致性模型**

上面的 JMM 内容可以了解到， 在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，这个写操作根本没有被当前线程所执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才对其他线程可见。在这种情况下，当前线程和其他线程看到的执行顺序是不一样的。 

### JMM 中同步程序的顺序一致性效果

-  JMM中，临界区内（同步块或同步方法中）的代码可以发生重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏锁的内存语义）；
  -  这种重排序既提高了执行效率，又没有改变程序的执行结果。
  -  JMM会在退出临界区和进入临界区做特殊的处理，使得在临界区内程序获得与顺序一致性模型相同的内存视图。

未同步程序在JMM和顺序一致性内存模型中的执行特性有如下差异：

1. 顺序一致性保证单线程内的操作会按程序的顺序执行；JMM不保证单线程内的操作会按程序的顺序执行。（因为重排序，但是JMM保证单线程下的重排序不影响执行结果）
2. 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。（因为JMM不保证所有操作立即可见）
3. 顺序一致性模型保证对所有的内存读写操作都具有原子性，而JMM不保证对64位的long型和double型变量的写操作具有原子性。

##  happens-before

 **JMM 的顺序一致性思想是只要不改变程序的执行结果（单线程程序和正确同步了的多线程程序），编译器和处理器怎么优化都行。**

**happens-before规则**（JSR-133规范） ： 满足了程序员的需求——**简单易懂，并且提供了足够强的内存可见性保证。** 就是说，只要满足 happens-before 就可以保证在JMM中具有强的内存可见性。

happens-before关系的定义如下：

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. **两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。**

>  happens-before关系本质上和as-if-serial语义是一回事。 
>
> as-if-serial语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的，happens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。 

总之，**如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的，不管它们在不在一个线程。** 

#### 天然的happens-before关系

- 程序顺序规则：一个线程中的每一个操作，happens-before于该线程中的任意后续操作。
- 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
- volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
- 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
- start规则：如果线程A执行操作ThreadB.start()启动线程B，那么A线程的ThreadB.start（）操作happens-before于线程B中的任意操作;
- join规则：如果线程A执行操作ThreadB.join（）并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

## volatile

**内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值**。

volatile 的内存语义

- 保证变量内存可见性
- 禁止 volatile 变量与普通变量重排序

### 内存可见性

 示例代码 ：

```java
public class VolatileExample {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1; // step 1
        flag = true; // step 2
    }

    public void reader() {
        if (flag) { // step 3
            System.out.println(a); // step 4
        }
    }
}
```

> 所谓内存可见性，指的是当一个线程对`volatile`修饰的变量进行**写操作**（比如step 2）时，JMM会立即把该线程对应的本地内存中的共享变量的值刷新到主内存；当一个线程对`volatile`修饰的变量进行**读操作**（比如step 3）时，JMM会把立即该线程对应的本地内存置为无效，从主内存中读取共享变量的值 

假设在时间线上，线程A先执行方法`writer`方法，线程B后执行`reader`方法。那必然会有下图：

<img src="https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-04.jpg" style="zoom: 80%;" />

<center>图04 volatile内存示意图</center>
而如果`flag`变量**没有**用`volatile`修饰，在step 2，线程A的本地内存里面的变量就不会立即更新到主内存，那随后线程B也同样不会去主内存拿最新的值，仍然使用线程B本地内存缓存的变量的值`a = 0，flag = false`。

### 禁止重排序

JSR-133之前的旧的Java内存模型中，是允许volatile变量与普通变量重排序的。那上面的案例中，可能就会被重排序成下列时序来执行： 

1. 线程A写volatile变量，step 2，设置flag为true；
2. 线程B读同一个volatile，step 3，读取到flag为true；
3. 线程B读普通变量，step 4，读取到 a = 0；
4. 线程A修改普通变量，step 1，设置 a = 1；

可见，如果volatile变量与普通变量发生了重排序，虽然volatile变量能保证内存可见性，也可能导致普通变量读取错误。 

#### 怎么限制重排序？

**理论**

通过**内存屏障**来实现的。

内存屏障分为两种：读屏障（Load Barrier）和写屏障（Store Barrier）。

屏障的两个作用：

1.  阻止屏障两侧的指令重排序；
2. 强制把写缓存区/高速缓存的脏数据等写回主内存，或者让缓存中相应的数据失效。

**实现**

 编译器在**生成字节码时**，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。编译器选择了一个**比较保守的JMM内存屏障插入策略**，这样可以保证在任何处理器平台，任何程序中都能得到正确的volatile内存语义。这个策略是：

- 在每个 volatile 写操作前插入一个 StoreStore 屏障；
- 在每个 volatile 写操作后插入一个 StoreLoad 屏障；
- 在每个 volatile 读操作后插入一个 LoadLoad 屏障；
- 在每个 volatile 读操作后再插入一个 LoadStore 屏障。

 大概示意图是这个样子： 

<img src="https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-05.png" style="zoom: 80%;" />

<center>图05 内存屏障</center>
-  **LoadLoad屏障**：对于这样的语句 Load1; LoadLoad; Load2 ，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
- **StoreStore屏障**：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，这个屏障会吧Store1强制刷新到内存，保证Store1的写入操作对其它处理器可见。 
-  **LoadStore屏障**：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 
-  **StoreLoad屏障**：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 

volatile与普通变量的重排序规则:

1. 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序；
2. 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序；
3. 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序。

我们在案例中step 1，是普通变量的写，step 2是volatile变量的写，那符合第2个规则，这两个steps不能重排序。而step 3是volatile变量读，step 4是普通变量读，符合第1个规则，同样不能重排序。 

## synchronized与锁

Java 6 以前 synchronized 锁机制是重量级锁，Java 6 之后对 synchronized 锁机制进行了优化，分别有四总级别的锁，由低到高：

- 无锁状态
- 偏向锁状态
- 轻量级锁状态
- 重量级锁状态

> Java 多线程的锁都是基于对象的，Java 中的每一个对象都可以作为一个锁。类锁也是对象锁。

### Java对象头

我们知道，Java 的锁都是基于对象的，而对象的锁的信息是存在什么地方的？

每个 Java 对象都有对象头分为两种情况：

1. 数组类型

   - 3个字宽来存储对象头；

     | 内容                     | 长度    | 说明                           |
     | :----------------------- | ------- | ------------------------------ |
     | Mark Word                | 1个字宽 | 存储对象的 hashCode 或锁信息等 |
     | Class Metadata Addresscc | 1个字宽 | 存储到对象类型数据的指针       |
     | Array length             | 1个字宽 | 数组的长度                     |

   

2. 非数组类型

   - 2个字宽来存储对象头；
   
      | 内容                     | 长度    | 说明                           |
      | :----------------------- | ------- | ------------------------------ |
      | Mark Word                | 1个字宽 | 存储对象的 hashCode 或锁信息等 |
      | Class Metadata Addresscc | 1个字宽 | 存储到对象类型数据的指针       |
   

 <font color='orange'>在32位处理器中，一个字宽是32位；在64位虚拟机中，一个字宽是64位</font> 。

#### Mark Work

主要来看看Mark Word的格式： 

| 锁状态   | 一个字宽 -  3bit             | 是否是偏向锁？(1bit) | 锁标志位（2bit） |
| -------- | ---------------------------- | -------------------- | ---------------- |
| 无锁     |                              | 0                    | 01               |
| 偏向锁   | 线程 ID                      | 1                    | 01               |
| 轻量级锁 | 指向栈中锁记录的指针         | 无效                 | 00               |
| 重量级锁 | 指向互斥量（重量级锁）的指针 | 无效                 | 10               |
| GC 标志  |                              | 无效                 | 11               |

其中， 当对象状态为偏向锁时，`Mark Word`存储的是偏向的线程ID；当状态为轻量级锁时，`Mark Word`存储的是指向线程栈中`Lock Record`的指针；当状态为重量级锁时，`Mark Word`为指向堆中的monitor对象的指针。 

### 偏向锁

**为什么需要偏向锁？**

研究发现大多数情况下**锁不仅不存在多线程竞争，而且总是由同一线程多次获得**，于是引入了偏向锁。(可重入锁)

**偏向锁的思路**

偏向锁会偏向于第一个访问锁的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发同步。也就是说，**偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能。** 

#### **实现原理**

-  一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的线程ID；
-  当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己的线程ID；
- 如果是，表明该线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；
-  如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换Mark Word里面的线程ID为新线程的ID；
-   这个时候要分两种情况： 
   1. 成功，表示之前的线程不存在了， Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁；
   2. 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁。

线程竞争偏向锁的过程如下： 

![](https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-06.jpg)

<center>图06   线程竞争偏向锁 </center>
其中，涉及到了lock record指针指向当前堆栈中的最近一个lock record，是轻量级锁按照先来先服务的模式进行了轻量级锁的加锁。 

#### 撤销偏向锁

偏向锁使用了一种**等到竞争出现才释放锁的机制**，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会撤销锁。

<font color='orange'>这里的撤销锁，是只锁升级成为轻量级锁，从微观上看的确是当前持有锁的线程释放了锁资源，如清空mark work线程ID， 设置偏向锁标识为0，并设置锁标志位为00 ；但是从宏观上，在锁升级完成后（轻量级锁）如果当前线程是在临界区内，则继续执行暂停的线程，这样看来当前线程并没有释放锁资源</font>。

> 参考： https://zhuanlan.zhihu.com/p/143479902 
>
> 偏向锁的撤销 
>
> 偏向锁的撤销并不是把对象恢复到无锁可偏向状态（因为偏向锁并不存在锁释放的概念），而是在获取偏向锁的过程中，发现CAS失败也就是存在线程竞争时，直接把被偏向的锁对象升级到被加了轻量级锁的状态。对原持有偏向锁的线程进行撤销时，原获得偏向锁的线程
> 有两种情况： 
>
> - 原获得偏向锁的线程如果已经退出了临界区，也就是同步代码块执行完了，那么这个时候会把对象头设置成无锁状态，同时正在争抢锁的线程可以基于 CAS 重新偏向当前线程。 
> - 如果原获得偏向锁的线程的同步代码块还没执行完，处于临界区之内，这个时候会把原获得偏向锁的线程升级为轻量级锁后继续执行同步代码块。

<img src="https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-07.png" style="zoom:80%;" />

<center>图07  偏向锁的获得和撤销 </center>
偏向锁升级成轻量级锁时，会暂停拥有偏向锁的线程，重置偏向锁标识 ，大概流程如下：

1. 在一个安全点（在这个时间点上没有字节码正在执行）停止拥有锁的线程。
2. <font color='orange'>遍历线程栈</font>，如果存在锁记录的话，需要修复锁记录和Mark Word，使其变成无锁状态。
3.  唤醒被停止的线程，将当前锁升级成轻量级锁。

关闭偏向锁

```java
-XX:UseBiasedLocking=false
```

### 轻量级锁

多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。

####  轻量级锁的加锁

- JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，我们称为Displaced Mark Word；
- 如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面；
-  然后线程尝试用CAS将锁的Mark Word替换为指向锁记录的指针；
-  如果成功，当前线程获得锁 
- 如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。 

自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源 。所以，JDK采用了更聪明的方式——**适应性自旋**，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 

自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会**升级成重量级锁**。 

#### 轻量级锁的释放

在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。 

<img src="https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/java/multiThread/04/04-08.png" style="zoom:80%;" />

<center>图08 轻量级锁流程图</center>
### 重量级锁

重量级锁依赖于操作系统的互斥量（mutex） 实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。 

```
Contention List：所有请求锁的线程将被首先放置到该竞争队列
Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List
Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set
OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck
Owner：获得锁的线程称为Owner
!Owner：释放锁的线程
```

- 当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个`ObjectWaiter`对象插入到Contention List的队列的队首，然后调用`park`函数挂起当前线程。 

- 当线程释放锁时，会从Contention List或EntryList中挑选一个线程唤醒，被选中的线程叫做`Heir presumptive`即假定继承人，假定继承人被唤醒后会尝试获得锁，但`synchronized`是非公平的，所以假定继承人不一定能获得锁。这是因为对于重量级锁，线程先自旋尝试获得锁，这样做的目的是为了减少执行操作系统同步操作带来的开销。如果自旋不成功再进入等待队列。这对那些已经在等待队列中的线程来说，稍微显得不公平，还有一个不公平的地方是自旋线程可能会抢占了Ready线程的锁 
-  如果线程获得锁后调用`Object.wait`方法，则会将线程加入到WaitSet中;
-  当被`Object.notify`唤醒后，会将线程从WaitSet移动到Contention List或EntryList中去 

需要注意的是，当调用一个锁对象的`wait`或`notify`方法时，**如当前锁的状态是偏向锁或轻量级锁则会先膨胀成重量级锁**。 

### 总结锁的升级流程 

每一个线程在准备获取共享资源时：

 第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。

第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空。

第三步，两个线程都把锁对象的<font color='orange'>HashCode</font>复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的MarKword的内容修改为自己新建的记录空间的地址的方式竞争MarkWord。

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败 。

第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。

### 各种锁的优缺点对比

| 锁       | 优点                                                         | 缺点                                             | 适用场景                             |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ------------------------------------ |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 | 适用于只有一个线程访问同步块场景。   |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度。                   | 如果始终得不到锁竞争的线程使用自旋会消耗CPU。    | 追求响应时间。同步块执行速度非常快。 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU。                            | 线程阻塞，响应时间缓慢。                         | 追求吞吐量。同步块执行时间较长。     |



## CAS与原子操作

### 悲观锁和乐观锁

**悲观锁**

悲观锁<font color='orange'>总是认为每次访问共享资源时会发生冲突</font>，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。

**乐观锁**

乐观锁<font color='orange'>总是假设对共享资源的访问没有冲突</font>，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。 

乐观锁多用于“读多写少“的环境，避免频繁加锁影响性能；而悲观锁多用于”写多读少“的环境，避免频繁失败和重试影响性能。 

### CAS

CAS (Compare And Swap),比较交换，有三个参数：

- V：要更新的值（var）
- E：预期值（expected）
- N：新值（new）

基本流程：

-  判断V是否等于E，如果等于，将V的值设置为N； 
-  如果不等，说明已经有其它线程更新了V，则当前线程放弃更新，什么都不做。 重新执行CAS

这里需要注意的是, <font color='orange'>CAS是一种原子操作</font>，它是一种系统原语，是一条CPU的原子指令，从CPU层面保证它的原子性。

CAS实现

在Java中，有一个`Unsafe`类，它在`sun.misc`包中。它里面是一些`native`方法，其中就有几个关于CAS的： 

```java
boolean compareAndSwapObject(Object o, long offset,Object expected, Object x);
boolean compareAndSwapInt(Object o, long offset,int expected,int x);
boolean compareAndSwapLong(Object o, long offset,long expected,long x);
```

Unsafe中对CAS的实现是C++写的，它的具体实现和操作系统、CPU都有关系。 

### CAS 实现原子操作的三大问题

- ABA 问题
  - ABA问题，就是一个值原来是A，变成了B，又变回了A。这个时候使用CAS是检查不出变化的，但实际上却被更新了两次。 
  - 解决： ABA问题的解决思路是在变量前面追加上**版本号或者时间戳**。
- 循环时间长开销大
  - CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。
  -  解决：思路是让JVM支持处理器提供的**pause指令** ， pause指令能让自旋失败时cpu睡眠一小段时间再继续自旋。
- 只能保证一个共享变量原子性操作
  - 解决：
    - 使用JDK 1.5开始就提供的`AtomicReference`类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作；
    - 使用锁。锁内的临界区代码可以保证只有当前线程能操作。

