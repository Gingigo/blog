# 行锁功过：怎么减少行锁对性能的影响？

MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一时刻只能有个一更新在执行，影响并发度。

我们以InnoDB的行锁为例，如何通过减少锁冲突来提升并发度。

**什么是行锁**，行锁是针对数据表中记录的锁。比如事务A要更新一行数据，而这时事务B也要更新这一行，则必须要等事务A的操作完成之后才能进行更新。

## 两阶段锁协议

举个例子，下面的操作顺序中，事务B的update语句执行时会是什么现象呢？假设字段id是t表的主键。

![](https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/database/mysql/mysql45/mysql45-07-01.jpg)

经过实践可知：实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。实践操作可得出结论是事务A持有的两个记录的行锁，都是在commit的时候释放的。

也就是说，**InnoDB事务中，行锁是在需要的时候才加上去的，但并不是不需要了就立即释放，而是要等到事务结束时才释放。这个就是两阶段锁协议**。

知道了这个设定，对我们使用事务有什么帮助呢？那就是，**如果你的事务中需要锁住多行，就要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

### 两阶段锁协议的实际应用

假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作：

1. 从顾客A账户余额中扣除电影票价；
2. 给电院B账户余额增加这张电影票价；
3. 记录一条交易日志。

也就是说，要完成这个交易，需要update两条记录，并insert一条记录。为了保证交易的原子性，我们要把三个操作放在同一个事务中。那如何安排执行顺序呢？

如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为需要更新同一个影院账户的余额，需要修改同一行数据。

根据两阶段协议，所有操作需要的行锁都是在事务提交的时候释放的，所以，把语句2安排在最后，那么影院账号这一行锁的时间最短，很大程度地减少了事务之间锁等待，提升并发。

好了，现在由于你正确地设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是这并没有完全解决你的困扰。

如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动开始的时候，你的MySQL就挂了。你登上服务器一看，CPU消耗接近100%整个数据库每秒就执行不到100个事务，这时什么原因呢？

## 死锁和死锁检测

**死锁是当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放巡检资源时，就会导致这几个线程都进入无限等待状态。**

我们用数据库中行锁说明死锁

![](https://raw.githubusercontent.com/dddygin/image-storage/main/blog/image/database/mysql/mysql45/mysql45-07-02.jpg)

可以从图中看出，事务A在等待事务B释放id为2的行锁，而此时事务B在等待事务A释放id为1的行锁。事务A和事务B在相互等待对方的资源释放，这就是进入死锁状态。

**死锁的两种策略**

- 第一种，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。

- 第二种，发起死锁检测，发现死锁后，主动回滚死锁中的某一个事务，让其他事务可以先继续执行。将参数innodb_deadlock_detect设置为on,表示开启这个逻辑。

在InnoDB中innodb_lock_wait_timeout的默认值是50s，这就意味着采取第一种策略，要经过50s才超时退出，然后其他线程才有可能继续执行，这样的时间太长了。但是如果把这个时间设置成一个很小的值，比如1s。这样当出现死锁的时候很快就能解开，但是不是死锁呢，而是简单的锁等待，这样会造成误伤。

**所有正常情况我们还是采用第二种策略，主动死锁检查，而且innodb_deadlock_detect的默认值是on。主动死锁检测在发生死锁的时候，能够快速发现并处理，但是是有额外的负担的。**主动死锁检查是根据每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待。

回到我们的开始的问题，如果所有事务都要更新同一行的场景呢？

根据死锁检查，每一个新来的被堵住的线程都要判断会不会由于自己的加入导致死锁，这是一个时间复杂度为O(n)的操作。假设有1000个并发线程同时要更新同一行，那么死锁检查操作就是1000*1000=100万这个量的。虽然检查的结构是没有死锁，但是这期间要消耗大量CPU资源。因此会看到CPU利用率很高，但是每秒却执行不了几个事务。

根据上面的分析，我们来讨论一下**怎么解决由于热点行更新导致的性能问题？**问题的根本是死锁检查需要消耗大量的CUP资源。

- **临时关掉死锁检查，前提是你能确保这个业务一定不会出现死锁**，但是这个本身有一定的风险，因为业务设计一般不会把死锁当成一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没有问题了，这时业务无损的。而关掉死锁检测意味着可能会出现大量超时，这时业务有损的。

- **控制并发度，如果上面的问题转为如果同一行只有10个线程在更新**,那么这样的死锁检测的成本就很低，不会出现这个问题。你会想直接在客户端做并发控制，但是你会发现这个方法不太行，假设1个客户端并发数为5，600个客户端就是3000，死锁检测要达到900万。因此要并发控制需要在数据库服务端，有中间件可以考虑中间件，其次有能力可以改源码，在进入引擎之前排队，这样就不会有大量的死锁检测了。**从逻辑上将用多行来替代一行也是可以减少并发度的**，比如影院有10个账号，这样冲突概率就1/10了，但是业务设计也是更加复杂了。

  

## 问题

1. 为什么关掉死锁检查会有可能出现大量的超时呢？

   因为如果出现死锁需要进入等待，直到超时（死锁策略一）

2. 什么是一致性读？

    答：[参考]( https://www.cnblogs.com/DataArt/p/10095339.html ) 















































