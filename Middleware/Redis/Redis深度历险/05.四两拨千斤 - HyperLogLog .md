## 05、 四两拨千斤 —— HyperLogLog 

如果你负责维护一个大型网站，产品经理要求获取每个网页每天的<font color='red'>UV（Unique Visitor ，独立访客）</font>的数据，让你来负责开发这个模块，要怎么实现呢？

如果是统计 <font color='red'>PV（ Page View,页面访问量））</font>那就非常好办，给每个网页一个独立的 Redis计数器就可以了，这个计数器 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。

但是，UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。这就要求每个网页请求都需要带上用户的 ID，无论是登录用户还是未登录用户都需要一个唯一 ID 来标识。

## 用 mysql 存储

需要建立一个表 t 

|  字段  |    类型     | 描述             |
| :----: | :---------: | ---------------- |
| userid | varchar(20) | 用户标识         |
|   d    |    date     | 日期（20200218） |

当一个请求过来的时候，要去判断数据库是否当前日期下，是否已经存在该用户的userId，如果存在不操作，否则，需要插入一条记录（用户唯一表示，当前日期）。

如需要统计UV的数量 直接执行 ：

```mysql
select count(*) from t where d='20200218';
```

获得UV的数据

**优点**：数据准确、业务逻辑清晰

**缺点**：在数据量大的情况下，几乎很容易就出现性能问题，性能差。

**总结**：缺点太过致命，如果量少还好说，并发三次，数据库hold 不住。

## 布隆过滤+MySQ

进一步优化的方案是：

1. 每一次请求都需要判断是否已经存在相同的记录
2. 持久化 UV 数据不能影响正常的业务
3. UV 数据的准确性能忍受存在一定的误差

设计数据库表为 t‘  

| 字段 |  类型   | 描述             |
| :--: | :-----: | ---------------- |
|  d   |  date   | 日期（20200218） |
| num  | int(11) | 访问数           |

处理流程如下：

1. 当一个请求过来的时候，经过布隆过滤，如果通过，则直接访问；
2. 如果通过，说明这个用户今天第一次访问,需要更新布隆过滤器，添加该访问请求的唯一标识 和 需要在数据库 num上加 1；
3. 设置定时任务，每天定时重置布隆过滤器；
4. 还可以集成 MQ 实现 数据的异步存储减少并发直接影响数据库的性能。

![](../../images/redis_deep_adventure/05-01.jpg)

<center>图1 布隆过滤和mysql 方式解决UV</center>

**优点**：数据存储量比之前少了，速度快了很多

**缺点**：设计复杂了，数据准确度下降（因为布隆过滤的原因）

**总结**：操作复杂，运维量上去了，放错的地方增多了，一定并发的时候是一个不错的选这，但是本质还没解决，就是操作数据库。例如在一段实际内用户开始登录，这是很多数据还在MQ 未进入到数据库统计，数据一直在消耗MQ 的数据，这是数据库的性能是差的。说白了，登录一千万人就要执行一千万条SQL。

## 布隆过滤+ Redis

因为""登录一千万人就要执行一千万条SQL" 这个并发量MySQ无法解决，但是 Redis 的吞吐量强，可以把MySQL 换成 Redis， Redis 新建一个 string 的数据结构 key 是时间，value 是登录人数 ，这样就可以通过 incr 增加数据了。

**优点** :数据存储量比之前少了，速度更快了；

**缺点**：设计简单点了，数据准确度下降（因为布隆过滤的原因）；

**总结** ：这是一个不错的选择，并发也是可以

##  HyperLogLog 

你可能会想，我都用了Redis，那我可以每一天建一个set存储，存储每一个用户访问的唯一标识，然后通过scard 取出集合的大小。这个的确是一个简单的方法，但是访问的人数上来，这个存储非常大，内存占用很耗资源。

那还有什么方法吗？

答案是有的，Redis 提供了 HyperLogLog 数据结构就是用来解决这种统计问题的。HyperLogLog 提供了相对准确的去重计数方案，标准误差是0.81%，这样的进度已经满足UV 统计需求了。

### 使用方法

HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面的意思很好理解，一个是增加计数，一个是获取计数。pfadd 用法和 set 集合的 sadd 是一样，来一个用户 ID，就将用户 ID 塞进去就是。pfcount 和 scard 用法是一样的，直接获取计数值。

```shell
127.0.0.1:6379> pfadd codehole user1
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 1
127.0.0.1:6379> pfadd codehole user2
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 2
127.0.0.1:6379> pfadd codehole user3
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 3
127.0.0.1:6379> pfadd codehole user3 user4 user5
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 5
```

简单试一下，发现精确的，一个不多一个不少，接下来我们用程序将数量增大：

```java
public class PfTest {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("192.168.99.100", 6379);
        int num = 100000;
        for (int i = 0; i < num; i++) {
            jedis.pfadd("codehole", "user" + i);
        }
        long total = jedis.pfcount("codehole");
        System.out.println(total);
        jedis.close();
    }
}
```

结果输出是

```shell
99725
```

10w 条数据，相差 275，按百分比是 0.275，相对上面的 UV 统计需求来说，误差不算高。然后我们把上面的脚本再跑一边，也就相当于将数据重复加入一边，查看输出，可以发现，pfcount 的结果没有任何改变，还是 99723，说明它确实具备去重功能。

#### pfmerge 适合什么场合？

HyperLogLog 除了上面的 pfadd 和 pfcount 之外，还提供了第三个指令 pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。

比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。其中页面的 UV 访问量也需要合并，那这个时候 pfmerge 就可以派上用场了。

##### 操作

```shell
127.0.0.1:6379> pfadd t1 1
(integer) 1
127.0.0.1:6379> pfadd t1 2
(integer) 1
127.0.0.1:6379> pfadd t1 3
(integer) 1
127.0.0.1:6379> pfadd t2 3
(integer) 1
127.0.0.1:6379> pfadd t2 4
(integer) 1
127.0.0.1:6379> pfcount t1
(integer) 3
127.0.0.1:6379> pfcount t2
(integer) 2
127.0.0.1:6379> pfmerge t1 t2
OK
127.0.0.1:6379> pfcount t1
(integer) 4
127.0.0.1:6379> pfcount t2
(integer) 2
127.0.0.1:6379> 
```

### 注意事项

HyperLogLog 需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。如果你的用户上亿，可以算算，这个空间成本是非常惊人的。但是相比 set 存储方案，HyperLogLog 所使用的空间那真是可以使用千斤对比四两来形容了。

不过你也不必过于当心，因为 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

### HyperLogLog 实现原理

为了方便理解 HyperLogLog 的内部实现原理，看一下下面的图。

![](../../images/redis_deep_adventure/05-02.jpg)



redis正是基于以上的HLL算法实现的[HyperLogLog](https://redis.io/commands#hyperloglog)结构，用于统计一组数据集合中不重复的数据个数。 redis中统计数组大小设置为16384 (2^14)，hash函数生成64位bit数组，其中14位用来找到统计数组的位置，剩下50位用来记录第一个1出现的位置，最大位置为50，需要6 (2^6=64>50) 位记录。 然后通过**伯努利试验**来估算总数是多少。当然，只是核心思路，真正的代码实现要不这个复杂的多。

现在你应该知道为什么HyperLogLog  最大需要占用 12k , 因为 6 * 2^14 bit = 12k。 

> 参考：
>
> 1. https://www.cnblogs.com/liliuguang/p/11112694.html 
>
> 2. https://blog.csdn.net/firenet1/article/details/77247649 